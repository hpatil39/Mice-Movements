{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mice Movement Tracking System in Linear Discriminant Analysis."
      ],
      "metadata": {
        "id": "HHgHZReCdKkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://data.caltech.edu/records/s0vdx-0k302/files/task1_classic_classification.zip?download=1\n",
        "! mv task1_classic_classification.zip?download=1 task1_classic_classification.zip\n",
        "! unzip task1_classic_classification.zip\n",
        "! wget https://data.caltech.edu/records/s0vdx-0k302/files/calms21_convert_to_npy.py?download=1\n",
        "! mv calms21_convert_to_npy.py?download=1 calms21_convert_to_npy.py\n",
        "! mkdir data\n",
        "! python calms21_convert_to_npy.py--input_directorytask1_classic_classification/--output_directory data/"
      ],
      "metadata": {
        "id": "6yUGw9PmdJ62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "JL-xcrjXdJ3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow"
      ],
      "metadata": {
        "id": "rBDtAdtDdJ1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('data/calms21_task1_test.npy', allow_pickle=True)\n",
        "data_dict = data.item()['annotator-id_0']\n",
        "print('test data length: ', len(list(data_dict.keys())), ' videos')\n",
        "data_tr = np.load('data/calms21_task1_train.npy', allow_pickle=True)\n",
        "data_dict_tr = data_tr.item()['annotator-id_0']\n",
        "print('train data length: ', len(list(data_dict_tr.keys())), ' videos')"
      ],
      "metadata": {
        "id": "lNzpupDBdJxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dict[list(data_dict.keys())[0]]['keypoints'].shape)\n",
        "print('(`# frames`) x (`mouse ID`) x (`x, y coordinate`) x (`body part`)')"
      ],
      "metadata": {
        "id": "OFtyWERwdJt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " for key in list(data_dict.keys()):\n",
        " mouse071 = data_dict[key]\n",
        " if len(np.unique(mouse071['annotations'])) ==4:\n",
        " break\n",
        " print(mouse071['keypoints'].shape) # (`# frames`) x (`mouse ID`) x (`x, y coordinate`) x (`body part`)\n",
        " print(mouse071['scores'].shape) # (`# frames`) x (`mouse ID`) x (`body part`)\n",
        " print(mouse071['annotations'], mouse071['metadata'])\n",
        " # 'keypoints'- tracked locations of body parts on the two interacting mice\n",
        " # 'scores'- confidence estimates for the tracked keypoints\n",
        " # 'annotations'- behaviors id"
      ],
      "metadata": {
        "id": "66oFdSibdJqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(mouse071['annotations'])"
      ],
      "metadata": {
        "id": "pxaOO3ThdJmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st mouse, id= 0\n",
        " body_parts_keypoints = [mouse071['keypoints'][:, :, 0, i] for i in range(7)]\n",
        " body_parts_keypoints_coords = dict()\n",
        " for i in range(7):\n",
        " body_parts_keypoints_coords[str(i) + '_x'] = body_parts_keypoints[i][:,0]\n",
        " body_parts_keypoints_coords[str(i) + '_y'] = body_parts_keypoints[i][:,1]\n",
        " body_parts_keypoints_coords[str(i) + '_score'] = mouse071['scores'][:, 0, i]\n",
        " df_mouse071_0 = pd.DataFrame(data=body_parts_keypoints_coords)\n",
        " df_mouse071_0['annotations'] = mouse071['annotations']\n",
        " df_mouse071_0.head()"
      ],
      "metadata": {
        "id": "p9RpTAzUdJgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd mouse, id= 1\n",
        " body_parts_keypoints = [mouse071['keypoints'][:, :, 1, i] for i in range(7)]\n",
        " body_parts_keypoints_coords = dict()\n",
        " for i in range(7):\n",
        " body_parts_keypoints_coords[str(i) + '_x'] = body_parts_keypoints[i][:,0]\n",
        " body_parts_keypoints_coords[str(i) + '_y'] = body_parts_keypoints[i][:,1]\n",
        " body_parts_keypoints_coords[str(i) + '_score'] = mouse071['scores'][:, 1, i]\n",
        " df_mouse071_1 = pd.DataFrame(data=body_parts_keypoints_coords)\n",
        " df_mouse071_1['annotations'] = mouse071['annotations']\n",
        " df_mouse071_1.head()"
      ],
      "metadata": {
        "id": "-x7_n1xkdJWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head_data = df_mouse071_0[['0_x', '0_y']]"
      ],
      "metadata": {
        "id": "kFn_L95BdJIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import matplotlib.pyplot as plt\n",
        " # Extract head data\n",
        " head_data = df_mouse071_0[['0_x', '0_y']]\n",
        " # Plot head data\n",
        " plt.figure(figsize=(8, 6))\n",
        " plt.scatter(head_data['0_x'], head_data['0_y'], s=10, c='b', marker='o')\n",
        " plt.title('Head Coordinates visualization')\n",
        " plt.xlabel('x-coordinate')\n",
        " plt.ylabel('y-coordinate')\n",
        " plt.grid(True)\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "D0S9qHMNdI4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.model_selection import train_test_split\n",
        " from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        " # Assuming df_mouse071_0 contains your DataFrame\n",
        " # Assuming the target variable is 'annotations'\n",
        " X = df_mouse071_0[['0_x', '0_y']] # Features"
      ],
      "metadata": {
        "id": "rCum1xq8eQQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_mouse071_0['annotations'] # Target variable\n",
        " # Split the data into training and testing sets\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,␣\n",
        " ↪random_state=42)\n",
        " # Initialize and fit the LDA model\n",
        " lda = LinearDiscriminantAnalysis()\n",
        " lda.fit(X_train, y_train)\n",
        " # Evaluate the model\n",
        " train_accuracy = lda.score(X_train, y_train)\n",
        " test_accuracy = lda.score(X_test, y_test)\n",
        " print(\"Training accuracy:\", train_accuracy)\n",
        " print(\"Testing accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "K4etcPjgeUCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        " import matplotlib.pyplot as plt\n",
        " # Assuming df_mouse071_0 contains your DataFrame\n",
        " X = df_mouse071_0[['0_x', '0_y']] # Features\n",
        " y = df_mouse071_0['annotations'] # Target variable\n",
        " # Split the data into training and testing sets\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,␣\n",
        " ↪random_state=42)\n",
        " plt.figure(figsize=(14,5))\n",
        " # Plot using svd solver\n",
        " plt.subplot(1,3,1)\n",
        " lda = LinearDiscriminantAnalysis(solver='svd')\n",
        " lda.fit(X_train, y_train)\n",
        " y_predict = lda.predict(X_test)\n",
        " plt.scatter(X_test['0_x'], y_test, s=10, c='b', marker=\"s\", label='testing')\n",
        " plt.scatter(X_test['0_x'], y_predict, s=10, c='r', marker=\"o\", label='predict')\n",
        " plt.legend()\n",
        " score = lda.score(X_test, y_test)\n",
        " plt.title('Accuracy of the svd solver is '+str(score))\n",
        " # Plot using lsqr solver\n",
        " plt.subplot(1,3,2)\n",
        " lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')"
      ],
      "metadata": {
        "id": "nI9jIRLYeant"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda.fit(X_train, y_train)\n",
        " y_predict = lda.predict(X_test)\n",
        " plt.scatter(X_test['0_x'], y_test, s=10, c='b', marker=\"s\", label='testing')\n",
        " plt.scatter(X_test['0_x'], y_predict, s=10, c='r', marker=\"o\", label='predict')\n",
        " plt.legend()\n",
        " score = lda.score(X_test, y_test)\n",
        " plt.title('Accuracy of the lsqr solver is '+str(score))\n",
        " # Plot using eigen solver\n",
        " plt.subplot(1,3,3)\n",
        " lda = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
        " lda.fit(X_train, y_train)\n",
        " y_predict = lda.predict(X_test)\n",
        " plt.scatter(X_test['0_x'], y_test, s=10, c='b', marker=\"s\", label='testing')\n",
        " plt.scatter(X_test['0_x'], y_predict, s=10, c='r', marker=\"o\", label='predict')\n",
        " plt.legend()\n",
        " score = lda.score(X_test, y_test)\n",
        " plt.title('Accuracy of the eigen solver is '+str(score))\n",
        " plt.tight_layout()\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "HBn5luzneT_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import numpy as np\n",
        " import matplotlib.pyplot as plt\n",
        " from sklearn.model_selection import train_test_split\n",
        " from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        " # Assuming head data is stored in X (features) and y (target variable)\n",
        " X = head_data[['0_x', '0_y']]\n",
        " y = df_mouse071_0['annotations']\n",
        " # Define range of testing sizes\n",
        " test_sizes = np.arange(0.05, 0.95, 0.05)\n",
        " accuracies = []\n",
        " # Iterate over different testing sizes\n",
        " for test_size in test_sizes:\n",
        " # Split the data into training and testing sets\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y,␣\n",
        " ↪test_size=test_size, random_state=42)\n",
        " # Initialize and fit the LDA model\n",
        " lda = LinearDiscriminantAnalysis()\n",
        " lda.fit(X_train, y_train)\n",
        " # Evaluate the model\n",
        " accuracy = lda.score(X_test, y_test)\n",
        " accuracies.append(accuracy)\n",
        " # Find the optimal test size with maximum accuracy\n",
        " optimal_test_size = test_sizes[np.argmax(accuracies)]\n",
        " max_accuracy = np.max(accuracies)\n",
        " print(\"Optimal Test Size:\", optimal_test_size)\n",
        " print(\"Maximum Accuracy:\", max_accuracy)\n",
        " # Plot accuracy vs. test size\n",
        " plt.plot(test_sizes, accuracies, marker='o')\n",
        " plt.title('Accuracy vs. Test Size')\n",
        " plt.xlabel('Test Size')\n",
        " plt.ylabel('Accuracy')\n",
        " plt.grid(True)\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "gUGBBLVceT8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neck Data"
      ],
      "metadata": {
        "id": "61NfAshleolp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        " # Extract neck data\n",
        " neck_data = df_mouse071_0[['1_x', '1_y']]\n",
        " # Plot neck data\n",
        " plt.figure(figsize=(8, 6))\n",
        " plt.scatter(neck_data['1_x'], neck_data['1_y'], s=10, c='r', marker='o')\n",
        " plt.title('Neck Coordinates visualization')\n",
        " plt.xlabel('x-coordinate')\n",
        " plt.ylabel('y-coordinate')\n",
        " plt.grid(True)\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "3m94BIQteT5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.model_selection import train_test_split\n",
        " from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        " # Assuming df_mouse071_0 contains your DataFrame\n",
        " # Assuming the target variable is 'annotations'\n",
        " X = df_mouse071_0[['1_x', '1_y']] # Features\n",
        " y = df_mouse071_0['annotations'] # Target variable\n",
        " # Split the data into training and testing sets\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,␣\n",
        " ↪random_state=42)\n",
        " # Initialize and fit the LDA model\n",
        " lda = LinearDiscriminantAnalysis()\n",
        " lda.fit(X_train, y_train)\n",
        " # Evaluate the model\n",
        " train_accuracy = lda.score(X_train, y_train)\n",
        " test_accuracy = lda.score(X_test, y_test)\n",
        " print(\"Training accuracy:\", train_accuracy)\n",
        " print(\"Testing accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "yAJP_T67eT2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        " import matplotlib.pyplot as plt\n",
        " # Assuming df_mouse071_0 contains your DataFrame\n",
        " X = df_mouse071_0[['1_x', '1_y']] # Features\n",
        " y = df_mouse071_0['annotations'] # Target variable\n",
        " # Split the data into training and testing sets\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,␣\n",
        " ↪random_state=42)\n",
        " plt.figure(figsize=(14,5))\n",
        " # Plot using svd solver\n",
        " plt.subplot(1,3,1)\n",
        " lda = LinearDiscriminantAnalysis(solver='svd')\n",
        " lda.fit(X_train, y_train)\n",
        " y_predict = lda.predict(X_test)\n",
        " plt.scatter(X_test['1_x'], y_test, s=10, c='b', marker=\"s\", label='testing')\n",
        " plt.scatter(X_test['1_x'], y_predict, s=10, c='r', marker=\"o\", label='predict')\n",
        " plt.legend()\n",
        " score = lda.score(X_test, y_test)\n",
        " plt.title('Accuracy of the svd solver is '+str(score))\n",
        " # Plot using lsqr solver\n",
        " plt.subplot(1,3,2)\n",
        " lda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
        " lda.fit(X_train, y_train)\n",
        " y_predict = lda.predict(X_test)\n",
        " plt.scatter(X_test['1_x'], y_test, s=10, c='b', marker=\"s\", label='testing')\n",
        " plt.scatter(X_test['1_x'], y_predict, s=10, c='r', marker=\"o\", label='predict')\n",
        " plt.legend()\n",
        " score = lda.score(X_test, y_test)\n",
        " plt.title('Accuracy of the lsqr solver is '+str(score))\n",
        " # Plot using eigen solver\n",
        " plt.subplot(1,3,3)\n",
        " lda = LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto')\n",
        " lda.fit(X_train, y_train)\n",
        " y_predict = lda.predict(X_test)\n",
        " plt.scatter(X_test['1_x'], y_test, s=10, c='b', marker=\"s\", label='testing')\n",
        " plt.scatter(X_test['1_x'], y_predict, s=10, c='r', marker=\"o\", label='predict')\n",
        " plt.legend()\n",
        " score = lda.score(X_test, y_test)\n",
        " plt.title('Accuracy of the eigen solver is '+str(score))\n",
        " plt.tight_layout()\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "qaXSWLmzeTy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Assuming df_mouse071_0 contains your DataFrame\n",
        " names = df_mouse071_0.columns.to_numpy()\n",
        " name_at_index_21 = names[21]\n",
        " print(name_at_index_21)\n",
        " column_names_array = df_mouse071_0.columns.to_numpy()\n",
        " print(column_names_array)"
      ],
      "metadata": {
        "id": "fLZAwKEIeTvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function of getting all the body parts and getting all the graphs at the same time"
      ],
      "metadata": {
        "id": "G3_tf_G8fAvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import matplotlib.pyplot as plt\n",
        " # Plot all data points\n",
        " plt.figure(figsize=(8, 6))\n",
        " for i in range(7): # Assuming you have 7 sets of coordinates\n",
        " x_col = f'{i}_x'\n",
        " y_col = f'{i}_y'\n",
        " plt.scatter(df_mouse071_0[x_col], df_mouse071_0[y_col], s=10, label=f'Point␣{i}')\n",
        " plt.title('All Body Parts Coordinates visualization')\n",
        " plt.xlabel('x-coordinate')\n",
        " plt.ylabel('y-coordinate')\n",
        " plt.legend()\n",
        " plt.grid(True)\n",
        " plt.show()\n"
      ],
      "metadata": {
        "id": "jKauCMVmeTpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data type of y_train:\", y_train.dtype)\n",
        " print(\"Data type of y_test:\", y_test.dtype)"
      ],
      "metadata": {
        "id": "m0VA59aYfTTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing accuracy improvement for body parts using LDA model for\n",
        "adding feature  "
      ],
      "metadata": {
        "id": "ylhKR7Azcj-i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNSJmFGEcf-5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Function to optimize accuracy for a given body part\n",
        "def optimize_accuracy(df, body_part):\n",
        "# Extract body part data and time data\n",
        "body_part_data = df[[f'{body_part}_x', f'{body_part}_y']]\n",
        "time_data = df['time']  # Assuming 'time' is the column name for time\n",
        "feature\n",
        "# Combine body part data and time data\n",
        "X = pd.concat([body_part_data, time_data], axis=1)\n",
        "y = df['annotations']\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.3, random_state=42)\n",
        "    # Initialize and fit the LDA model\n",
        "    lda = LinearDiscriminantAnalysis()\n",
        "    lda.fit(X_train, y_train)\n",
        "    # Calculate accuracy before optimization\n",
        "    accuracy_before_optimization = lda.score(X_test, y_test)\n",
        "    # Initialize variables to store optimized parameters and accuracy\n",
        "    best_test_size = 0.3\n",
        "    best_accuracy = accuracy_before_optimization\n",
        "    accuracy = []\n",
        "    test_sizes = []\n",
        "    # Perform optimization by changing the test size\n",
        "    for test_size in np.arange(0.1, 0.9, 0.1):\n",
        "        # Split data with the optimized test size\n",
        "        X_train_optimized, X_test_optimized, y_train_optimized,\n",
        "y_test_optimized = train_test_split(X, y, test_size=test_size,\n",
        "random_state=42)\n",
        "        # Fit the model with the optimized data\n",
        "        lda.fit(X_train_optimized, y_train_optimized)\n",
        "        # Calculate accuracy after optimization\n",
        "        accuracy_after_optimization = lda.score(X_test_optimized,\n",
        "y_test_optimized)\n",
        "        accuracy.append(accuracy_after_optimization)\n",
        "        test_sizes.append(test_size)\n",
        "        # Update best accuracy and test size if improvement is found\n",
        "        if accuracy_after_optimization > best_accuracy:\n",
        "            best_accuracy = accuracy_after_optimization\n",
        "            best_test_size = test_size\n",
        "    # Calculate accuracy improvement\n",
        "    accuracy_improvement = best_accuracy - accuracy_before_optimization\n",
        "    # Perform K-Means clustering\n",
        "    # Extract body part data and time data\n",
        "    body_part_data = df[[f'{body_part}_x', f'{body_part}_y']]\n",
        "    time_data = df['time']  # Assuming 'time' is the column name for time\n",
        "feature\n",
        "    # Combine body part data and time data\n",
        "    X_cluster = pd.concat([body_part_data, time_data], axis=1)\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    body_part_data_scaled = scaler.fit_transform(X_cluster)\n",
        "    # Initialize the K-Means clustering model\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42)  # Assuming 2 clusters\n",
        "for each body part\n",
        "    # Fit the model to the data\n",
        "    kmeans.fit(body_part_data_scaled)\n",
        "    # Get the cluster labels for each data point\n",
        "    labels = kmeans.labels_\n",
        "    # Add the cluster labels to the original DataFrame\n",
        "    df[f'{body_part}_cluster'] = labels\n",
        "    return accuracy_improvement, best_test_size\n",
        "# Assuming df_mouse071_0 contains the DataFrame for mouse 071\n",
        "# Define the list of body parts\n",
        "body_parts = ['0', '1', '2', '3', '4', '5', '6']\n",
        "# Initialize a dictionary to store accuracy improvements and best test\n",
        "sizes for each body part\n",
        "accuracy_improvements = {}\n",
        "best_test_sizes = {}\n",
        "# Iterate over each body part and optimize accuracy\n",
        "for body_part in body_parts:\n",
        "    accuracy_improvement, best_test_size = optimize_accuracy(df_mouse071_0,\n",
        "body_part)\n",
        "    accuracy_improvements[body_part] = accuracy_improvement\n",
        "    best_test_sizes[body_part] = best_test_size\n",
        "# Plot the accuracy improvements as a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(accuracy_improvements.keys(), accuracy_improvements.values())\n",
        "plt.xlabel('Body Part')\n",
        "plt.ylabel('Accuracy Improvement')\n",
        "plt.title('Accuracy Improvement after adding feature')\n",
        "plt.show()\n",
        "# Print the best test sizes for each body part\n",
        "print(\"Best Test Sizes:\")\n",
        "for body_part in body_parts:\n",
        "    print(f\"Body Part {body_part}: {best_test_sizes[body_part]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing accuracy improvement for body parts using LDA model for Adding Time\n",
        "Feature and Changing Test Size"
      ],
      "metadata": {
        "id": "XB3CvOaicqH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function to optimize accuracy for a given body part\n",
        "def optimize_accuracy(df, body_part):\n",
        "    # Extract body part data and time data\n",
        "    body_part_data = df[[f'{body_part}_x', f'{body_part}_y', 'time']]\n",
        "\n",
        "    # Split the data into features (X) and target variable (y)\n",
        "    X = body_part_data\n",
        "    y = df['annotations']\n",
        "\n",
        "    # Initialize and fit the LDA model\n",
        "    lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "    # Calculate accuracy for default test size\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.3, random_state=42)\n",
        "    lda.fit(X_train, y_train)\n",
        "    accuracy_default = lda.score(X_test, y_test)\n",
        "\n",
        "    # Initialize variables to store best accuracy and parameters\n",
        "    best_accuracy = accuracy_default\n",
        "    best_test_size = 0.3\n",
        "    best_time_added = False\n",
        "\n",
        "    # Try different test sizes and check accuracy improvement after\n",
        "adding time feature\n",
        "    for test_size in np.arange(0.1, 0.9, 0.1):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=test_size, random_state=42)\n",
        "        lda.fit(X_train, y_train)\n",
        "        accuracy_test_size = lda.score(X_test, y_test)\n",
        "\n",
        "        # Add time feature\n",
        "        X_train['time'] = np.random.rand(X_train.shape[0])  #\n",
        "Placeholder for actual time data\n",
        "        X_test['time'] = np.random.rand(X_test.shape[0])  # Placeholder\n",
        "for actual time data\n",
        "\n",
        "        lda.fit(X_train, y_train)\n",
        "        accuracy_with_time = lda.score(X_test, y_test)\n",
        "\n",
        "        # Check if accuracy improved\n",
        "        if accuracy_with_time > best_accuracy:\n",
        "            best_accuracy = accuracy_with_time\n",
        "            best_test_size = test_size\n",
        "            best_time_added = True\n",
        "\n",
        "    accuracy_improvement = best_accuracy - accuracy_default\n",
        "\n",
        "    return accuracy_improvement, best_test_size, best_time_added\n",
        "\n",
        "# Assuming df_mouse071_0 contains the DataFrame for mouse 071\n",
        "# Define the list of body parts\n",
        "body_parts = ['0', '1', '2', '3', '4', '5', '6']\n",
        "\n",
        "# Initialize dictionaries to store accuracy improvements, best test\n",
        "sizes, and time added\n",
        "accuracy_improvements = {}\n",
        "best_test_sizes = {}\n",
        "time_added = {}\n",
        "\n",
        "# Iterate over each body part and optimize accuracy\n",
        "for body_part in body_parts:\n",
        "    accuracy_improvement, best_test_size, time_added_flag =\n",
        "optimize_accuracy(df_mouse071_0, body_part)\n",
        "    accuracy_improvements[body_part] = accuracy_improvement\n",
        "    best_test_sizes[body_part] = best_test_size\n",
        "    time_added[body_part] = time_added_flag\n",
        "\n",
        "# Plot the accuracy improvements as a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(accuracy_improvements.keys(), accuracy_improvements.values())\n",
        "plt.xlabel('Body Part')\n",
        "plt.ylabel('Accuracy Improvement')\n",
        "plt.title('Accuracy Improvement after Adding Time Feature and Changing\n",
        "Test Size')\n",
        "plt.show()\n",
        "\n",
        "# Print the best test sizes for each body part\n",
        "print(\"Best Test Sizes:\")\n",
        "for body_part in body_parts:\n",
        "    print(f\"Body Part {body_part}: {best_test_sizes[body_part]}\")\n",
        "\n",
        "# Print whether time feature was added for each body part\n",
        "print(\"\\nTime Feature Added:\")\n",
        "for body_part in body_parts:\n",
        "    print(f\"Body Part {body_part}: {'Yes' if time_added[body_part] else\n",
        "'No'}\")"
      ],
      "metadata": {
        "id": "4Gh5reMvckP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing accuracy improvement for body parts using LDA model for changing solver"
      ],
      "metadata": {
        "id": "V0p_i6cpcyXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function to optimize accuracy for a given body part\n",
        "def optimize_accuracy(df, body_part):\n",
        "    # Extract body part data and time data\n",
        "    body_part_data = df[[f'{body_part}_x', f'{body_part}_y', 'time']]\n",
        "\n",
        "    # Split the data into features (X) and target variable (y)\n",
        "    X = body_part_data\n",
        "    y = df['annotations']\n",
        "\n",
        "    # Initialize variables to store best accuracy and parameters\n",
        "    best_accuracy = 0\n",
        "    best_solver = None\n",
        "\n",
        "    # Try different solvers and check accuracy improvement after adding\n",
        "time feature\n",
        "    solvers = ['svd', 'lsqr', 'eigen']\n",
        "    for solver in solvers:\n",
        "        # Initialize and fit the LDA model with the current solver\n",
        "        lda = LinearDiscriminantAnalysis(solver=solver)\n",
        "\n",
        "        # Calculate accuracy for default test size\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.3, random_state=42)\n",
        "        lda.fit(X_train, y_train)\n",
        "        accuracy_default = lda.score(X_test, y_test)\n",
        "\n",
        "        # Add time feature\n",
        "        X_train['time'] = np.random.rand(X_train.shape[0])  #\n",
        "Placeholder for actual time data\n",
        "        X_test['time'] = np.random.rand(X_test.shape[0])  # Placeholder\n",
        "for actual time data\n",
        "\n",
        "        lda.fit(X_train, y_train)\n",
        "        accuracy_with_time = lda.score(X_test, y_test)\n",
        "\n",
        "        # Check if accuracy improved\n",
        "        accuracy_improvement = accuracy_with_time - accuracy_default\n",
        "        if accuracy_improvement > best_accuracy:\n",
        "            best_accuracy = accuracy_improvement\n",
        "            best_solver = solver\n",
        "\n",
        "    return best_accuracy, best_solver\n",
        "\n",
        "# Assuming df_mouse071_0 contains the DataFrame for mouse 071\n",
        "# Define the list of body parts\n",
        "body_parts = ['0', '1', '2', '3', '4', '5', '6']\n",
        "\n",
        "# Initialize dictionaries to store accuracy improvements and best\n",
        "solvers\n",
        "accuracy_improvements = {}\n",
        "best_solvers = {}\n",
        "\n",
        "# Iterate over each body part and optimize accuracy\n",
        "for body_part in body_parts:\n",
        "    accuracy_improvement, best_solver =\n",
        "optimize_accuracy(df_mouse071_0, body_part)\n",
        "    accuracy_improvements[body_part] = accuracy_improvement\n",
        "    best_solvers[body_part] = best_solver\n",
        "\n",
        "# Plot the accuracy improvements as a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(accuracy_improvements.keys(), accuracy_improvements.values())\n",
        "plt.xlabel('Body Part')\n",
        "plt.ylabel('Accuracy Improvement')\n",
        "plt.title('Accuracy Improvement after Changing Solver')\n",
        "plt.show()\n",
        "\n",
        "# Print the best solvers for each body part\n",
        "print(\"Best Solvers:\")\n",
        "for body_part in body_parts:\n",
        "    print(f\"Body Part {body_part}: {best_solvers[body_part]}\")"
      ],
      "metadata": {
        "id": "MCgr_yp8czAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing accuracy improvement for body parts using LDA model for changing solver\n",
        "and changing test size"
      ],
      "metadata": {
        "id": "oyej0QCuc4-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function to optimize accuracy for a given body part\n",
        "def optimize_accuracy(df, body_part):\n",
        "    # Extract body part data and time data\n",
        "    body_part_data = df[[f'{body_part}_x', f'{body_part}_y', 'time']]\n",
        "\n",
        "    # Split the data into features (X) and target variable (y)\n",
        "    X = body_part_data\n",
        "    y = df['annotations']\n",
        "\n",
        "    # Initialize variables to store best accuracy and parameters\n",
        "    best_accuracy = 0\n",
        "    best_solver = None\n",
        "    best_test_size = 0\n",
        "\n",
        "    # Try different solvers and test sizes and check accuracy\n",
        "improvement after adding time feature\n",
        "    solvers = ['svd', 'lsqr', 'eigen']\n",
        "    for solver in solvers:\n",
        "        for test_size in np.arange(0.1, 0.9, 0.1):\n",
        "            # Initialize and fit the LDA model with the current solver\n",
        "            lda = LinearDiscriminantAnalysis(solver=solver)\n",
        "\n",
        "            # Calculate accuracy for the current test size\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=test_size, random_state=42)\n",
        "            lda.fit(X_train, y_train)\n",
        "            accuracy_default = lda.score(X_test, y_test)\n",
        "\n",
        "            # Add time feature\n",
        "            X_train['time'] = np.random.rand(X_train.shape[0])  #\n",
        "Placeholder for actual time data\n",
        "            X_test['time'] = np.random.rand(X_test.shape[0])  #\n",
        "Placeholder for actual time data\n",
        "\n",
        "            lda.fit(X_train, y_train)\n",
        "            accuracy_with_time = lda.score(X_test, y_test)\n",
        "\n",
        "            # Check if accuracy improved\n",
        "            accuracy_improvement = accuracy_with_time -\n",
        "accuracy_default\n",
        "            if accuracy_improvement > best_accuracy:\n",
        "                best_accuracy = accuracy_improvement\n",
        "                best_solver = solver\n",
        "                best_test_size = test_size\n",
        "\n",
        "    return best_accuracy, best_solver, best_test_size\n",
        "\n",
        "# Assuming df_mouse071_0 contains the DataFrame for mouse 071\n",
        "# Define the list of body parts\n",
        "body_parts = ['0', '1', '2', '3', '4', '5', '6']\n",
        "\n",
        "# Initialize dictionaries to store accuracy improvements, best solvers,\n",
        "and best test sizes\n",
        "accuracy_improvements = {}\n",
        "best_solvers = {}\n",
        "best_test_sizes = {}\n",
        "\n",
        "# Iterate over each body part and optimize accuracy\n",
        "for body_part in body_parts:\n",
        "    accuracy_improvement, best_solver, best_test_size =\n",
        "optimize_accuracy(df_mouse071_0, body_part)\n",
        "    accuracy_improvements[body_part] = accuracy_improvement\n",
        "    best_solvers[body_part] = best_solver\n",
        "    best_test_sizes[body_part] = best_test_size\n",
        "\n",
        "# Plot the accuracy improvements as a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(accuracy_improvements.keys(), accuracy_improvements.values())\n",
        "plt.xlabel('Body Part')\n",
        "plt.ylabel('Accuracy Improvement')\n",
        "plt.title('Accuracy Improvement after Changing Solver and Test Size')\n",
        "plt.show()\n",
        "\n",
        "# Print the best solvers and test sizes for each body part\n",
        "print(\"Best Solvers and Test Sizes:\")\n",
        "for body_part in body_parts:\n",
        "    print(f\"Body Part {body_part}: Solver - {best_solvers[body_part]},\n",
        "Test Size - {best_test_sizes[body_part]}\")"
      ],
      "metadata": {
        "id": "Llwr5Xftc5f1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}